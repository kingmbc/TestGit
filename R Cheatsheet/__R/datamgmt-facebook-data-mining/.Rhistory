access.token <- "AAACEdEose0cBAJwJsmfKPy8J93MiSwWQYZCSVMXvP0qMIMLjvrdxZCjMJo0fNQ1mng2PyL3EpjczMVUi2yWO1SEVZCDZB2EZD"
getwd()
# Facebook - hacking the social network
# Step 1: Get a Facebook Graph API Explorer Access Token
# Go to 'https://developers.facebook.com/tools/explorer', login and click "Get access token"
# Store your access token here:
cat("Step 1: Get a Facebook Graph API Explorer Access Token","\n")
source("AccessToken.R")
# Step 2: Add the userid of the individual whose social network you want to examine
# By default this is "me" but otherwise it should be an individuals facebook id
cat("Step 2: Add the userid of the individual whose social network you want to examine","\n")
individual.id <- "me"
file.seqno <- 1
# Step 3: Fetch data about the selected individual
cat("Step 3: Fetch data about the selected individual","\n")
source("Individual.R")
# Step 4: Fetch data about the individuals friends
cat("Step 4: Fetch data about the individuals friends","\n")
source("Friends.R")
# Facebook - hacking the social network
# Step 1: Get a Facebook Graph API Explorer Access Token
# Go to 'https://developers.facebook.com/tools/explorer', login and click "Get access token"
# Store your access token here:
cat("Step 1: Get a Facebook Graph API Explorer Access Token","\n")
source("AccessToken.R")
# Step 2: Add the userid of the individual whose social network you want to examine
# By default this is "me" but otherwise it should be an individuals facebook id
cat("Step 2: Add the userid of the individual whose social network you want to examine","\n")
individual.id <- "me"
file.seqno <- 1
# Step 3: Fetch data about the selected individual
cat("Step 3: Fetch data about the selected individual","\n")
source("Individual.R")
# This installs (if required) and loads the mandatory libaries for this demo
# Required CRAN packages
package.list <- c("igraph", "network", "pixmap", "RCurl", "ReadImages", "rjson", "adimpro")
for (i in 1:length(package.list)) {
pkg <- package.list[i]
if(!IsInstalled(pkg)) {
install.packages(pkg)
}
require(pkg, character.only = TRUE)
}
source("Setup.R")
source("Demo.R")
source("Setup.R")
source("Demo.R")
install.packages("KoNLP")
install.packages("devtools")
install_github("KoNLP", "haven-jeon",ref="KoNLP_0.76.5")
library(KoNLP)
library(wordcloud)
library(twitteR)
library(KoNLP)
library(wordcloud)
library(tm)
require(wordcloud)
install.packages("twitteR")
install.packages("KoNLP")
install.packages("wordcloud")
install.packages("tm")
library(twitteR)
library(KoNLP)
library(wordcloud)
library(tm)
n1=100
nn <- c(1:n1)
keywd<-"대통령"
keywd<-enc2utf8(keywd)
result<-searchTwitter(keywd, n=n1)
resulttext <- c()
for(i in nn){
resulttext <- append(resulttext, enc2utf8(result[[i]]$text))
}
resulttext <- gsub("\n","", resulttext)
resulttext <- gsub("\r", "", resulttext)
resulttext <- gsub("co", "", resulttext)
resulttext <- gsub("http", "", resulttext)
resulttext <- gsub("!", "", resulttext)
resulttext <- gsub("?", "", resulttext)
#resulttext <- gsub(".", "", resulttext)
resulttext <- gsub("ㅋ", "", resulttext)
resulttext <- gsub("ㅜ", "", resulttext)
resulttext <- gsub("ㅠ", "", resulttext)
resulttext <- gsub("ㅎ", "", resulttext)
resulttext <- gsub("RT", "", resulttext)
nouns <- Map(extractNoun, resulttext)
wordsvec <- unlist(nouns, use.name=F)
#쓸모없는 문자들을 제거한다. 특히 영문자의 경우 tm의 stopwords를 활용한다.
wordsvec <- wordsvec[-which(wordsvec %in% stopwords("english"))]
wordsvec <- gsub("[[:punct:]]","", wordsvec)
wordsvec <- Filter(function(x){nchar(x)>=2}, wordsvec)
wordcount <- table(wordsvec)
pal <- brewer.pal(8,"Dark2")
wordcloud(names(wordcount),freq=wordcount,scale=c(4,1.5),min.freq=10, random.order=T,rot.per=.1,colors=pal)
install.packages("KoNLP")
install.packages("devtools")
install_github("KoNLP", "haven-jeon",ref="KoNLP_0.76.5")
library(KoNLP)
library(wordcloud)
library(plyr)
library(devtools)
ahn = readLines("dat/ahn.txt")
getwd()
